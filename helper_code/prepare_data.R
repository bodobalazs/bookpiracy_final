#DATA SETUP - prepare all data
library(tidyverse)

#load EUrostat variables. Contains the followind frames:
#bookpiracy - all EUROSTAT data generated by XXXXXX
#bookpiracy_var_stat - data description
#bookpiracy_wide - 
#landuse - 
load ("raw_data/bookpiracy_2020-04-15.rda") 

# load the Eurobarometer variable
# The data is available and described in on Zenodo
# at https://zenodo.org/record/3759811#.XqKbj2gzbIU
# a longer description of the methodology can be found 
# https://figshare.com/articles/Regionalized_Cultural_Access_and_Participation_Books_And_Libraries_And_Science_Attitudes_Variables/12170190

eurobarometer <- read.csv (
  file.path('raw_data', 
            'books_library_eurobarometer_79_2.csv'), 
  stringsAsFactors = FALSE) 

## The Eurobarometer survey fieldwork took place in April-May
## 2013 and most the questions relate to the previous 12 months.

eb_vars <- eurobarometer %>%
  dplyr::select ( geo, indicator, values, method )

# merge the data ---------------------------------------------------
# add number of researchers per region 
researchers <- bookpiracy %>%
  dplyr::select ( geo, indicator, values, method ) %>%
  filter ( indicator == 'rd_p_persreg_total_t_total_fte' ) %>%
  dplyr::select ( geo, values, method ) %>%
  mutate ( indicator  = 'researchers_total' )

# add percentage of researchers
bookpiracy_long <- bookpiracy %>%
  filter ( ! grepl("rd_p_persreg", indicator )) %>%
  dplyr::select ( geo, values, indicator, method ) %>%
  rbind ( ., researchers ) %>%
  rbind (., eb_vars )

# The geodata is a administrative boundary map of the NUTS2 regions in the
# NUTS2016 definitions, as provided by Eurostat and Eurographics.
# We translated the shapefile to an sf object for easier handling. 

geodata <- readRDS ( 'raw_data/geodata.rds' )

# add download counts 
# the data was prepared by .....R

download_data <- readRDS( file.path("raw_data","downloads_nuts_2016.rds")
) %>%
  dplyr::rename ( geo = id, 
                  values = count ) %>%
  dplyr::mutate ( indicator = 'count',
                  method = 'actual' ) %>%
  filter ( geo %in% bookpiracy_long$geo ) %>%
  mutate ( values = ifelse(is.na(values), 0, values))

# rename variables to meaningful names -------------------------
indicator_renaming <- read.csv("raw_data/indicator_renaming.csv", 
                               stringsAsFactors = FALSE)

unique(bookpiracy_long$indicator) # var names BEFORE renaming

# nuts2dataset is the base dataframe for the analysis n long format 
# it contains incomplete cases

nuts2_dataset <- bookpiracy_long %>%
  left_join (  indicator_renaming, by = "indicator")  %>%
  mutate ( indicator = ifelse(is.na(new_name), 
                              indicator, new_name) ) %>%
  mutate ( indicator = gsub("erobarometer_79_2_|eurobarometer_79_2_", "", indicator)) %>%
  dplyr::select (-new_name ) %>%
  rbind(., download_data ) 

unique(nuts2_dataset$indicator) # var names AFTER renaming

# create data frame with different relative dowload counts 

nuts2_data  <- nuts2_dataset %>%
  dplyr::select ( -method ) %>% # all 2013 filtered
  tidyr::spread ( indicator, values ) %>%
  dplyr::mutate ( count_per_million = round(1000000*count / population_total),
                  count_per_capita = count / population_total, 
                  count_per_area   = count / area_land_filled,
                  count_per_thousand_researchers = round(1000*count / researchers_total),
                  count_per_researcher  = count / researchers_total) %>%
  dplyr::mutate ( count_per_pop_density = {count /
      ( population_total / area_land_filled)} ,
      count_per_researcher = {
        count / researchers_total } ) 


#complete_df is the base dataset for analysis. it only contains complete cases
complete_df <- nuts2_data %>% 
  filter ( complete.cases(.) )

#create datasets with scaled varibles
nuts2_dataset_scaled <- nuts2_data %>%
  dplyr::mutate_if( is.numeric, scale )  

complete_scaled <- complete_df %>%
  dplyr::mutate_if( is.numeric, scale ) %>%
  dplyr::mutate_if( is.numeric, as.numeric)

dataset_source_statistics <- nuts2_dataset %>%
  add_count ( indicator, method ) %>%
  distinct ( indicator, method, n  ) %>%
  spread ( method, n )

#nuts2_dataset_scaled_by_geo <- nuts2_dataset_scaled %>%
#  dplyr::filter ( !is.na(count)) %>%
#  dplyr::mutate ( missings = rowSums(is.na(.))) %>%
#  dplyr::arrange ( rev(missings) ) 

#scaled_wide <- nuts2_dataset_scaled_by_geo %>%
#  dplyr::filter ( missings == 0 ) 

#scaled <- scaled_wide %>%
#  dplyr::select ( -missings ) %>%
#  gather ( indicator_name, values, -one_of("geo"))  %>%
#  dplyr::mutate ( values = as.numeric(values)) 
save(complete_df, complete_scaled, nuts2_data, 
     nuts2_dataset_scaled,dataset_source_statistics, 
     geodata,
     file="raw_data/all_data_for_analysis.rda") # THIS SHOULD GO TO /data

save(complete_df, complete_scaled, nuts2_data, 
     nuts2_dataset_scaled,dataset_source_statistics, 
     geodata,
     file="data/all_data_for_analysis.rda")
