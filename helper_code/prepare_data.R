#DATA SETUP - prepare all data
library(tidyverse)


#load EUrostat variables. Contains the followind frames:
#bookpiracy - all EUROSTAT data generated by XXXXXX
#bookpiracy_var_stat - data description
#bookpiracy_wide - 
#landuse - 
load ("raw_data/bookpiracy_2020-04-15.rda") 


#add number of researchers per region
researchers <- bookpiracy %>%
  dplyr::select ( geo, indicator, values, method ) %>%
  filter ( indicator == 'rd_p_persreg_total_t_total_fte' ) %>%
  dplyr::select ( geo, values, method ) %>%
  mutate ( indicator  = 'researchers_total' )

#add percentage of researchers 
bookpiracy_long <- bookpiracy %>%
  filter ( ! grepl("rd_p_persreg", indicator )) %>%
  dplyr::select ( geo, values, indicator, method ) %>%
  rbind ( ., researchers )

geodata <- readRDS ( 'raw_data/geodata.rds' )

#add download counts
download_data <- readRDS( file.path("raw_data","downloads_nuts_2016.rds")
) %>%
  dplyr::rename ( geo = id, 
                  values = count ) %>%
  dplyr::mutate ( indicator = 'count',
                  method = 'actual' ) %>%
  filter ( geo %in% bookpiracy_long$geo ) %>%
  mutate ( values = ifelse(is.na(values), 0, values))

#rename variables to human readble names
indicator_renaming <- read.csv("raw_data/indicator_renaming.csv", 
                               stringsAsFactors = FALSE)

unique(bookpiracy_long$indicator)


#nuts2dataset is the base dataframe for the analysis n long format it contains incomplete cases
nuts2_dataset <- bookpiracy_long %>%
  left_join (  indicator_renaming, by = "indicator")  %>%
  mutate ( indicator = ifelse(is.na(new_name), 
                              indicator, new_name) ) %>%
  dplyr::select (-new_name ) %>%
  rbind(., download_data ) 
unique(nuts2_dataset$indicator)

#create DF with different relative dowload counts 
nuts2_data  <- nuts2_dataset %>%
  dplyr::select ( -method ) %>% # all 2013 filtered
  tidyr::spread ( indicator, values ) %>%
  dplyr::mutate ( count_per_million = round(1000000*count / population_total),
                  count_per_capita = count / population_total, 
                  count_per_area   = count / area_land_filled,
                  count_per_thousand_researchers = round(1000*count / researchers_total),
                  count_per_researcher  = count / researchers_total) %>%
  dplyr::mutate ( count_per_pop_density = {count /
      ( population_total / area_land_filled)} ,
      count_per_researcher = {
        count / researchers_total } ) 


#complete_df is the base dataset for analysis. it only contains complete cases
complete_df <- nuts2_data %>% 
  filter ( complete.cases(.) )

#create datasets with scaled varibles
nuts2_dataset_scaled <- nuts2_data %>%
  dplyr::mutate_if( is.numeric, scale )  

complete_scaled <- complete_df %>%
  dplyr::mutate_if( is.numeric, scale ) %>%
  dplyr::mutate_if( is.numeric, as.numeric)

dataset_source_statistics <- nuts2_dataset %>%
  add_count ( indicator, method ) %>%
  distinct ( indicator, method, n  ) %>%
  spread ( method, n )

#nuts2_dataset_scaled_by_geo <- nuts2_dataset_scaled %>%
#  dplyr::filter ( !is.na(count)) %>%
#  dplyr::mutate ( missings = rowSums(is.na(.))) %>%
#  dplyr::arrange ( rev(missings) ) 

#scaled_wide <- nuts2_dataset_scaled_by_geo %>%
#  dplyr::filter ( missings == 0 ) 

#scaled <- scaled_wide %>%
#  dplyr::select ( -missings ) %>%
#  gather ( indicator_name, values, -one_of("geo"))  %>%
#  dplyr::mutate ( values = as.numeric(values)) 
save(complete_df, complete_scaled, nuts2_data, 
     nuts2_dataset_scaled,dataset_source_statistics, 
     geodata, file="raw_data/all_data_for_analysis.rda")
